{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author: Kyle Cochran\n",
    "\n",
    "Intro:\n",
    "======\n",
    "Hi there. Cloud predict is a simple (or maybe not so simple) tool for improving cloud coverage predictions by using Planet Labs imagery. This can be done a whole bunch of ways, [outlined here](https://docs.google.com/document/d/1kd3TzlZg3vgJ8R7Jv20ztRru72tKuW-nnQ6g78knWHM/edit#heading=h.spyidnqefqz8). Two ways are implemented in the `cloudpredict.py` Python file. Examples of how to run each are given below.\n",
    "\n",
    "If any of this is difficult to run as a notebook (because planet dependencies), the 'main' function inside `cloudpredict.py` has these examples and is easier to run inside of Docker.\n",
    "\n",
    "For those interested in continuing, the code is marked up with `TODO:` statements in areas that could still use work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'planet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bd5e7cf5b2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcloudpredict\u001b[0m \u001b[0;31m#main file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotmat\u001b[0m \u001b[0;31m# uber-simple matrix loader, colorer, and plotter I made\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplanetingress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplani\u001b[0m \u001b[0;31m# Used for retrieving Planet data + some helper functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/ops/components/python/planet.ops.metis/planet/ops/metis/cloudpredict/cloudpredict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplanet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeasibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanagers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclouds\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnoaai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplanetingress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplani\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mosgeo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'planet'"
     ]
    }
   ],
   "source": [
    "import cloudpredict #main file\n",
    "import plotmat # uber-simple matrix loader, colorer, and plotter I made\n",
    "import planetingress as plani # Used for retrieving Planet data + some helper functions\n",
    "\n",
    "import numpy as np\n",
    "import matplot.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases, you first must define an area you wish to predict. The format for defining this is the same as the \"geometry\" sub-structure of a geojson file. You can only define one polygon at a time.\n",
    "\n",
    "The geometry here is this region of San Francisco which is particularly interesting because half is usually clear and the other half is usually cloudy:\n",
    "\n",
    "<img src=\"notebook_stuff/sf_predict_area.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This can be any single shape, but the code internally draws a rectangle \n",
    "    around and uses that  it to make pixels easier.\n",
    "'''\n",
    "geoaoi = {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -122.48485565185547,\n",
    "              37.74004179435127\n",
    "            ],\n",
    "            [\n",
    "              -122.43232727050781,\n",
    "              37.74004179435127\n",
    "            ],\n",
    "            [\n",
    "              -122.43232727050781,\n",
    "              37.77695634643178\n",
    "            ],\n",
    "            [\n",
    "              -122.48485565185547,\n",
    "              37.77695634643178\n",
    "            ],\n",
    "            [\n",
    "              -122.48485565185547,\n",
    "              37.74004179435127\n",
    "            ]\n",
    "          ]\n",
    "        ]\n",
    "      }\n",
    "\n",
    "    '''\n",
    "        The time that we're trying to predict. \n",
    "        \n",
    "        This needs to be in the future to work (for the linear predicter) and needs to be in the _nearish_ future to work well.\n",
    "        \n",
    "        !! : change this to be in the future : !!\n",
    "    '''\n",
    "    prediction_time = datetime.datetime(2019, 9, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamical systems PDE-FINDing method\n",
    "---------------------\n",
    "This method uses Planet imagery to try and reconstruct a PDE that successfully models local weather patterns as a dynamical system. Cloud coverage maps over time are extracted from Planet imagery and stacked into a 3D matrix. Numerical methods are then used to approximate derivatives and the PDE-FIND method is used to reconstruct a best-fit PDE. Theory documentation for PDE-FIND can be found [at Arxiv here](https://arxiv.org/abs/1609.06401) and the open source code implementation can be found [on github here](https://github.com/snagcliffs/PDE-FIND). A more extensive explanation of our implementation and notes on how to continue can be found [in this google doc](https://docs.google.com/document/d/1r-uGVuRmNgy-l3tDs4OEH6mRriXnRUR3QzsJah6p44I/edit#heading=h.lpxx7rdo1tvk). \n",
    "\n",
    "NOTE: while PDE generation works well, solving arbitrary PDE's to make predictions proved to be too difficult. It is likely that this method will provide a highly accurate/precise prediction if a robust PDE solving method is devised. \n",
    "\n",
    "\n",
    "##### Generating a PDE ##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Define the period on which to train the pde model\n",
    "'''\n",
    "dtstart = datetime.datetime(2019, 8, 11)\n",
    "dtend= datetime.datetime(2019, 9, 11)\n",
    "\n",
    "'''\n",
    "   Find a PDE model for the weather in that area at that time.\n",
    "   \n",
    "   'c' is a list of coefficients (just floats)\n",
    "   'description' is a list of strings that describes the terms in the PDE\n",
    "   \n",
    "   This function also parses the description internally and \n",
    "   saves the PDE to a file in a more machine friendly format\n",
    "'''\n",
    "c, description = cloudpredict.findPDE(geoaoi, dtstart, dtend)\n",
    "\n",
    "\n",
    "# Print it out in a human-friendly way\n",
    "cloudpredict.printPDE(c, description, ut = 'cov_t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting the weather with a PDE #####\n",
    "\n",
    "This is the tricky part, and unfortunately still doesn't really work. Attempts were made using [Fenics](https://fenicsproject.org/). To see my attempts, check out the [jupyter notebook](\"file://notebook_stuff/pdesim.ipynb\") for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cloudpredict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1d5017ad5ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mPDE\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m '''\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcloudpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictPDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeoaoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cloudpredict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = \"path to where the model is saved locally\"\n",
    "\n",
    "'''\n",
    "Uses the latest Planet imagery as initial conditions and solve the\n",
    "PDE given in 'model'\n",
    "'''\n",
    "cloudpredict.predictPDE(geoaoi, prediction_time, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First Order Bias and Correction Method\n",
    "---------------------\n",
    "This method is a much simpler approach that was written up in a week when the first method was abandoned. Starting with the base NOAA prediction for a given time, two correction steps are applied: \n",
    "\n",
    "#### NOAA bias drift correction ####\n",
    "This step uses two data points in the past to approximate bias drift in NOAA predictions. Planet cloud cover masks are taken to be an absolute-truth model. \n",
    "Two times are taken from the past:\n",
    "- *time B* should be at least a day back (this is a tuning parameter)\n",
    "- *time A* should be as close to the present as possible and be at a time when Planet imagery is available\n",
    "\n",
    "\n",
    "At `B`, we ask NOAA for a prediction _generated at that time_ of the cloud cover _at the newer time_. That is, we ask NOAA what they _would have given_ for a prediction of `A` if asked at `B`. We compare that to the Planet imagery to figure out how wrong the prediction was.\n",
    "\n",
    "We then ask for another prediction of the cloud coverage at `A` given at a time that is _pretty close to_ `A`. \"pretty close\" is determined by the NOAA data cadence but is usually around 12 hours. We then compare _this_ prediction to the Planet imagery to determine how wrong it is. Since this prediction is not as far into the future, we expect it to be a bit better. \n",
    "\n",
    "The change in the \"correctness\" of the NOAA prediction is what I've called _bias drift_. The two bias values generated can be used to find the rate of change in bias (bias drift). This value is then used to linearly exptrapolate the expected bias into the future.\n",
    "\n",
    "#### Local area bias correction ####\n",
    "Within an region of interest, there can often be smaller scale fluctuations in cloud cover that are not accounted for by the NOAA prediction. A good example is San Francisco. The city is split by a mountain range into the \"usually cloudy\" western half and the \"usually clear\" eastern half. This step averages the pixel difference from the NOAA prediction for the past `n` Planet images. That per-pixel bias is then assumed to hold for any images in the future.\n",
    "\n",
    "Each Planet image is binned into some smaller dimension with bigger pixels (for computations sake). The difference in cloudiness between each big pixel and the NOAA prediction is taken to create a \"bias map\" for each image in time. These images are averaged over time to generate one \"bias map\". This bias map indicates, for each pixel, how far off the truth usually is from the NOAA prediction. To get a map of the future, just add the NOAA prediction to this bias map.\n",
    "\n",
    "Sematic NOTE: At one point we add a probability to a pixel average. This is \"what is the likelyhood of this whole area being cloudy\" + \"what percent of this area was cloudy\". This uses the interpretation of probability as the likelihood of choosing a clouding location from drawing a single point in an area and is completely valid. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long to look into the past to find trends\n",
    "hist_days = 5\n",
    "\n",
    "'''\n",
    "    Makes the prediction\n",
    "   \n",
    "   returns:\n",
    "       predict: (float) an prediction of the whole (boxed in) area, without counting regional effects\n",
    "       predict_map: (2d Numpy array) a binned map of the (boxed in) area, counts regional effects\n",
    "'''\n",
    "predict, predict_map = predict_linear(geoaoi, prediction_time, history_days = hist_days)\n",
    "\n",
    "\n",
    "# This saves the predict map matrix to a file so we can later check it against actual weather pix\n",
    "p_time_str = plani.datetime_to_ISO8601Z(prediction_time)\n",
    "now = plani.datetime_to_ISO8601Z(datetime.datetime.now())\n",
    "filename = p_time_str + \"_\" + now + \"_\" + str(hist_days)\n",
    "testfolder = \"./tests/\"\n",
    "# looks like \"./tests/2019-09-06T00:00:00.000000Z_2019-09-05T21:36:45.314072Z_5.npy\"\n",
    "np.save(testfolder + filename, predict_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a prediction of : 2019-09-06T00:00:00.000000Z\n",
    "Made at             : 2019-09-05T21:36:45.314072Z\n",
    "Using a history of  : 5 days\n",
    "\n",
    "\n",
    "original NOAA predict :\t\t 0.00032899\n",
    "corrected predict     : \t 0.14808152\n",
    "\n",
    "The locally corrected predict maps look like:\n",
    "<img src=\"notebook_stuff/predict_map_example.png\">\n",
    "\n",
    "The closest PlanetScope image was taken at: 2019-09-05T18:34:51.000000Z\n",
    "\n",
    "And looks like :\n",
    "<img src=\"notebook_stuff/planetscope_validation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Remarks ###\n",
    "\n",
    "Although validation should be performed in more areas, the initial results here look promising. The linear approximation method shows significant increase in accuracy over the bare NOAA prediction for the San Francisco test case (NOAA predicted almost no clouds at all). The predicter clearly identifies the likelihood that it will be cloudier overall than the NOAA prediction, and correctly identifies the regions that are likely to be extra cloudy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neato, but how do prod?\n",
    "========================\n",
    "\n",
    "Glad you asked. To get this working in an automated prod-friendly way, there are a couple of things that could still be done:\n",
    "\n",
    "##### Turn the predict maps into a single number (sort of)\n",
    "To do this, we could just average over the predict map, easy. OR, we could define the region of interest as much larger than what we're actually interested in, do the prediction on that, then take our region of interest as a single pixel inside of the predict map.\n",
    "\n",
    "##### Test in more locations\n",
    "This is the obvious one, but San Francisco is sort of an edge case where I _expect_ this approach to do well. What happens in normal places?\n",
    "\n",
    "##### Maybe make getting the NOAA weather predictions a bit faster (optional)\n",
    "The NOAA weather prediction code was really only ever meant to predict the future. I had to hack it in order to sort of \"predict the present from the past\". Makes it kind of slow.\n",
    "\n",
    "##### Fetch Planet data locally instead of using the public API (optional)\n",
    "Grab images from the storage buckets instead of using the peoples interface. Might involve some local georectification, but would make us not have to wait for the whole \"activation\" then \"downloading\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
